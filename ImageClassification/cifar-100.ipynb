{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Title\nDescription","metadata":{}},{"cell_type":"markdown","source":"### Step 0: Function that checks if libraries are imported for different environments","metadata":{}},{"cell_type":"code","source":"# Import the necessary libraries\nimport importlib  # Allows for runtime importing of modules\nimport subprocess  # Allows for the execution of bash commands within Python\n\n# Define the function that checks the modules' installation status and import them\ndef check_installed_and_import(import_dict):\n    # Iterate over the dictionary items\n    for module, imported_as in import_dict.items():\n        try:\n            # Attempt to import the module using importlib\n            imported_module = importlib.import_module(module)\n            # If the import is successful, add the module to the global namespace under the 'imported_as' alias\n            globals()[imported_as] = imported_module\n            # Print a success message\n            print(f\"{module} imported as {imported_as}\")\n        # If the import fails, catch the exception\n        except Exception as e:\n            # Print a failure message\n            print(f\"FAILED: {module} imported as {imported_as}. Trying to install...\")\n            try:\n                # Try to install the module using pip via the subprocess module\n                base_module = module.split(\".\")[0]  # Get the base module, in case we're trying to import a submodule\n                subprocess.check_call(['pip', 'install', base_module])\n                # Try to import the module again\n                imported_module = importlib.import_module(module)\n                # If the import is successful this time, add the module to the global namespace under the 'imported_as' alias\n                globals()[imported_as] = imported_module\n                # Print a success message\n                print(f\"{module} imported as {imported_as}\")\n            # If the import still fails, catch the exception\n            except Exception as e:\n                # Print a final failure message along with the exception message\n                print(f\"FAILED: {module} imported as {imported_as}. Error: {e}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:53:41.267359Z","iopub.execute_input":"2023-08-02T20:53:41.267755Z","iopub.status.idle":"2023-08-02T20:53:41.279262Z","shell.execute_reply.started":"2023-08-02T20:53:41.267726Z","shell.execute_reply":"2023-08-02T20:53:41.276211Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Step 1a:  Import necessary libraries","metadata":{}},{"cell_type":"code","source":"# Call the function with our dictionary to check the modules' installation and import them\ncheck_installed_and_import({\n    'graphviz': 'graphviz',\n    #'IPython.display': 'Ipy',\n    'kerastuner': 'kerastuner',\n    'kerastuner.tuners': 'tuners',\n    'os': 'os',\n    'matplotlib.pyplot': 'plt',\n    'numpy': 'np',\n    'pydot': 'pydot',\n    'tensorflow': 'tf',\n    'tensorflow.keras': 'keras',\n    'tensorflow.keras.callbacks': 'callbacks',\n    'tensorflow.keras.layers': 'layers',\n    'tensorflow.keras.models': 'models',\n    'tensorflow.keras.optimizers': 'optimizers',\n    'tensorflow.keras.mixed_precision': 'mixed_precision',\n    'tensorflow.keras.utils': 'utils',\n    'tensorflow.keras.preprocessing.image': 'image',    \n})\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-02T20:58:57.772332Z","iopub.execute_input":"2023-08-02T20:58:57.773399Z","iopub.status.idle":"2023-08-02T20:58:57.781817Z","shell.execute_reply.started":"2023-08-02T20:58:57.773363Z","shell.execute_reply":"2023-08-02T20:58:57.780517Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"graphviz imported as graphviz\nkerastuner imported as kerastuner\nkerastuner.tuners imported as tuners\nos imported as os\nmatplotlib.pyplot imported as plt\nnumpy imported as np\npydot imported as pydot\ntensorflow imported as tf\ntensorflow.keras imported as keras\ntensorflow.keras.callbacks imported as callbacks\ntensorflow.keras.layers imported as layers\ntensorflow.keras.models imported as models\ntensorflow.keras.optimizers imported as optimizers\ntensorflow.keras.mixed_precision imported as mixed_precision\ntensorflow.keras.utils imported as utils\ntensorflow.keras.preprocessing.image imported as image\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 1b:  Speeding things up.","metadata":{}},{"cell_type":"code","source":"# Enable mixed precision training\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:59:37.763831Z","iopub.execute_input":"2023-08-02T20:59:37.764225Z","iopub.status.idle":"2023-08-02T20:59:37.769528Z","shell.execute_reply.started":"2023-08-02T20:59:37.764193Z","shell.execute_reply":"2023-08-02T20:59:37.768107Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Step 1c:  variables for flow control","metadata":{}},{"cell_type":"code","source":"keras_tuning = True","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:59:38.876482Z","iopub.execute_input":"2023-08-02T20:59:38.876856Z","iopub.status.idle":"2023-08-02T20:59:38.882571Z","shell.execute_reply.started":"2023-08-02T20:59:38.876827Z","shell.execute_reply":"2023-08-02T20:59:38.881242Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Step 2: Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Load the CIFAR-100 dataset\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n\n# Normalize the data (scale pixel values between 0 and 1)\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\n\n# Convert labels to one-hot encoded vectors\nnum_classes = 100\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\n# Data augmentation\ndata_gen = image.ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n)\ndata_gen.fit(x_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:59:40.552833Z","iopub.execute_input":"2023-08-02T20:59:40.553820Z","iopub.status.idle":"2023-08-02T20:59:41.759544Z","shell.execute_reply.started":"2023-08-02T20:59:40.553773Z","shell.execute_reply":"2023-08-02T20:59:41.758545Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Build the CNN Architecture","metadata":{}},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()\nif keras_tuning:\n    def build_model(hp):\n        with strategy.scope():\n            model = models.Sequential()\n            model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n            model.add(layers.MaxPooling2D((2, 2)))\n            model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n            model.add(layers.MaxPooling2D((2, 2)))\n            model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n            model.add(layers.Flatten())\n            model.add(layers.Dense(256, activation='relu'))\n            model.add(layers.Dense(num_classes, activation='softmax'))\n\n            # Use hp.Choice to select learning rate\n            lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n\n            model.compile(optimizer=optimizers.Adam(learning_rate=lr),\n                        loss='categorical_crossentropy',\n                        metrics=['accuracy'])\n            return model\n    tuner = tuners.RandomSearch(\n        build_model,\n        objective='val_accuracy',\n        max_trials=5,\n        executions_per_trial=3,\n        directory='my_dir',\n        project_name='Keras_Tuned_CIFAR-100')\n\n    tuner.search(x_train, y_train,\n                epochs=5,\n                validation_data=(x_test, y_test))\n\nelse:\n    model = models.Sequential()\n    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Dropout(0.2))\n\n    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Dropout(0.4))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(256, activation='relu'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(num_classes, activation='softmax'))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:59:43.852933Z","iopub.execute_input":"2023-08-02T20:59:43.853337Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\nSearch: Running Trial #1\n\nValue             |Best Value So Far |Hyperparameter\n0.001             |0.001             |learning_rate\n\nEpoch 1/5\n1493/1563 [===========================>..] - ETA: 0s - loss: 3.7803 - accuracy: 0.1217","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 4: Compile the Model","metadata":{}},{"cell_type":"code","source":"opt = optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nplot = utils.plot_model(model, show_shapes=True, show_layer_names=True)\nplot.savefig(\"model.png\")\nImage(filename='model.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 5: Training the Model","metadata":{}},{"cell_type":"code","source":"epochs = 50\nbatch_size = 64\nearly_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nhistory = model.fit(\n    data_gen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=len(x_train) / batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    callbacks=[early_stopping]\n)\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 6: Evaluate the Model","metadata":{}},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 7: Fine-tuning","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}