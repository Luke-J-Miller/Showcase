{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Title\nDescription","metadata":{}},{"cell_type":"markdown","source":"### Step 0: Function that checks if libraries are imported for different environments","metadata":{}},{"cell_type":"code","source":"# Import the necessary libraries\nimport importlib  # Allows for runtime importing of modules\nimport subprocess  # Allows for the execution of bash commands within Python\n\n# Define the function that checks the modules' installation status and import them\ndef check_installed_and_import(import_dict):\n    # Iterate over the dictionary items\n    for module, imported_as in import_dict.items():\n        try:\n            # Attempt to import the module using importlib\n            imported_module = importlib.import_module(module)\n            # If the import is successful, add the module to the global namespace under the 'imported_as' alias\n            globals()[imported_as] = imported_module\n            # Print a success message\n            print(f\"{module} imported as {imported_as}\")\n        # If the import fails, catch the exception\n        except Exception as e:\n            # Print a failure message\n            print(f\"FAILED: {module} imported as {imported_as}. Trying to install...\")\n            try:\n                # Try to install the module using pip via the subprocess module\n                base_module = module.split(\".\")[0]  # Get the base module, in case we're trying to import a submodule\n                subprocess.check_call(['pip', 'install', base_module])\n                # Try to import the module again\n                imported_module = importlib.import_module(module)\n                # If the import is successful this time, add the module to the global namespace under the 'imported_as' alias\n                globals()[imported_as] = imported_module\n                # Print a success message\n                print(f\"{module} imported as {imported_as}\")\n            # If the import still fails, catch the exception\n            except Exception as e:\n                # Print a final failure message along with the exception message\n                print(f\"FAILED: {module} imported as {imported_as}. Error: {e}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T19:37:24.616058Z","iopub.execute_input":"2023-08-02T19:37:24.616462Z","iopub.status.idle":"2023-08-02T19:37:24.632737Z","shell.execute_reply.started":"2023-08-02T19:37:24.616425Z","shell.execute_reply":"2023-08-02T19:37:24.631682Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Step 1a:  Import necessary libraries","metadata":{}},{"cell_type":"code","source":"# Call the function with our dictionary to check the modules' installation and import them\ncheck_installed_and_import({\n    'graphviz': 'graphviz',\n    'IPython.display.Image': 'Img',\n    'os': 'os',\n    'matplotlib.pyplot': 'plt'\n    'numpy': 'np',\n    'pydot': 'pydot',\n    'tensorflow': 'tf',\n    'tensorflow.keras': 'keras',\n    'tensorflow.keras.callbacks': 'callbacks',\n    'tensorflow.keras.layers': 'layers',\n    'tensorflow.keras.models': 'models',\n    'tensorflow.keras.optimizers': 'optimizers',\n    'tensorflow.keras.mixed_precision.experimental': 'experimental',\n    'tensorflow.keras.utils.plot_model', 'plot_model'\n    'tensorflow.keras.preprocessing.image': 'image',    \n})","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-02T19:37:24.634712Z","iopub.execute_input":"2023-08-02T19:37:24.635109Z","iopub.status.idle":"2023-08-02T19:37:33.668410Z","shell.execute_reply.started":"2023-08-02T19:37:24.635069Z","shell.execute_reply":"2023-08-02T19:37:33.667192Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"os imported as os\nnumpy imported as np\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"tensorflow imported as tf\ntensorflow.keras imported as keras\ntensorflow.keras.layers imported as layers\ntensorflow.keras.models imported as models\ntensorflow.keras.preprocessing.image imported as image\ntensorflow.keras.callbacks imported as callbacks\ntensorflow.keras.optimizers imported as optimizers\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 1b:  Speeding things up.","metadata":{}},{"cell_type":"code","source":"# Enable mixed precision training\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_policy(policy)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 1c:  variables for flow control","metadata":{}},{"cell_type":"code","source":"keras_tuning = True","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2: Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Load the CIFAR-100 dataset\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n\n# Normalize the data (scale pixel values between 0 and 1)\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\n\n# Convert labels to one-hot encoded vectors\nnum_classes = 100\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\n# Data augmentation\ndata_gen = image.ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n)\ndata_gen.fit(x_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T19:37:33.670410Z","iopub.execute_input":"2023-08-02T19:37:33.671460Z","iopub.status.idle":"2023-08-02T19:37:38.211649Z","shell.execute_reply.started":"2023-08-02T19:37:33.671412Z","shell.execute_reply":"2023-08-02T19:37:38.210504Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n169001437/169001437 [==============================] - 2s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 3: Build the CNN Architecture","metadata":{}},{"cell_type":"code","source":"if keras_tuning:\n    def build_model(hp):\n        model = models.Sequential()\n        model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n        model.add(layers.MaxPooling2D((2, 2)))\n        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n        model.add(layers.MaxPooling2D((2, 2)))\n        model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n        model.add(layers.Flatten())\n        model.add(layers.Dense(256, activation='relu'))\n        model.add(layers.Dense(num_classes, activation='softmax'))\n\n        # Use hp.Choice to select learning rate\n        lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n\n        model.compile(optimizer=optimizers.Adam(learning_rate=lr),\n                    loss='categorical_crossentropy',\n                    metrics=['accuracy'])\n        return model\n    tuner = RandomSearch(\n        build_model,\n        objective='val_accuracy',\n        max_trials=5,\n        executions_per_trial=3,\n        directory='my_dir',\n        project_name='Keras_Tuned_CIFAR-100')\n\n    tuner.search(x_train, y_train,\n                epochs=5,\n                validation_data=(x_test, y_test))\n\ntuner = RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=5,\n    executions_per_trial=3,\n    directory='my_dir',\n    project_name='helloworld')\n\ntuner.search(x_train, y_train,\n            epochs=5,\n            validation_data=(x_test, y_test))\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(num_classes, activation='softmax'))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-02T19:37:38.213487Z","iopub.execute_input":"2023-08-02T19:37:38.213854Z","iopub.status.idle":"2023-08-02T19:37:42.827126Z","shell.execute_reply.started":"2023-08-02T19:37:38.213821Z","shell.execute_reply":"2023-08-02T19:37:42.826058Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Step 4: Compile the Model","metadata":{}},{"cell_type":"code","source":"opt = optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nplot = plot_model(model, show_shapes=True, show_layer_names=True)\nplot.savefig(\"model.png\")\nImage(filename='model.png')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T19:37:42.830044Z","iopub.execute_input":"2023-08-02T19:37:42.830748Z","iopub.status.idle":"2023-08-02T19:37:42.854225Z","shell.execute_reply.started":"2023-08-02T19:37:42.830713Z","shell.execute_reply":"2023-08-02T19:37:42.853232Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Step 5: Training the Model","metadata":{}},{"cell_type":"code","source":"epochs = 50\nbatch_size = 64\nearly_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nhistory = model.fit(\n    data_gen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=len(x_train) / batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    callbacks=[early_stopping]\n)\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T19:37:42.858526Z","iopub.execute_input":"2023-08-02T19:37:42.861352Z","iopub.status.idle":"2023-08-02T20:07:17.008959Z","shell.execute_reply.started":"2023-08-02T19:37:42.861319Z","shell.execute_reply":"2023-08-02T20:07:17.007927Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2023-08-02 19:37:45.389270: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"781/781 [==============================] - 50s 45ms/step - loss: 4.1079 - accuracy: 0.1020 - val_loss: 3.6259 - val_accuracy: 0.1516\nEpoch 2/50\n781/781 [==============================] - 33s 42ms/step - loss: 3.2313 - accuracy: 0.2139 - val_loss: 2.8451 - val_accuracy: 0.2929\nEpoch 3/50\n781/781 [==============================] - 33s 42ms/step - loss: 2.7838 - accuracy: 0.2914 - val_loss: 2.9503 - val_accuracy: 0.2816\nEpoch 4/50\n781/781 [==============================] - 34s 43ms/step - loss: 2.5086 - accuracy: 0.3483 - val_loss: 2.2082 - val_accuracy: 0.4140\nEpoch 5/50\n781/781 [==============================] - 33s 42ms/step - loss: 2.3094 - accuracy: 0.3933 - val_loss: 2.1290 - val_accuracy: 0.4408\nEpoch 6/50\n781/781 [==============================] - 33s 42ms/step - loss: 2.1888 - accuracy: 0.4162 - val_loss: 1.9608 - val_accuracy: 0.4757\nEpoch 7/50\n781/781 [==============================] - 33s 43ms/step - loss: 2.0813 - accuracy: 0.4404 - val_loss: 1.8370 - val_accuracy: 0.4972\nEpoch 8/50\n781/781 [==============================] - 35s 44ms/step - loss: 1.9862 - accuracy: 0.4618 - val_loss: 1.9323 - val_accuracy: 0.4801\nEpoch 9/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.9175 - accuracy: 0.4802 - val_loss: 1.8252 - val_accuracy: 0.5073\nEpoch 10/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.8514 - accuracy: 0.4931 - val_loss: 1.6899 - val_accuracy: 0.5325\nEpoch 11/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.8010 - accuracy: 0.5075 - val_loss: 1.6967 - val_accuracy: 0.5343\nEpoch 12/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.7463 - accuracy: 0.5189 - val_loss: 1.6599 - val_accuracy: 0.5449\nEpoch 13/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.7057 - accuracy: 0.5292 - val_loss: 1.7436 - val_accuracy: 0.5377\nEpoch 14/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.6678 - accuracy: 0.5381 - val_loss: 1.7645 - val_accuracy: 0.5285\nEpoch 15/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.6304 - accuracy: 0.5459 - val_loss: 1.7383 - val_accuracy: 0.5475\nEpoch 16/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.6021 - accuracy: 0.5538 - val_loss: 1.7498 - val_accuracy: 0.5334\nEpoch 17/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.5710 - accuracy: 0.5622 - val_loss: 1.5235 - val_accuracy: 0.5811\nEpoch 18/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.5324 - accuracy: 0.5723 - val_loss: 1.5829 - val_accuracy: 0.5742\nEpoch 19/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.5125 - accuracy: 0.5741 - val_loss: 1.4950 - val_accuracy: 0.5924\nEpoch 20/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.4927 - accuracy: 0.5837 - val_loss: 1.4316 - val_accuracy: 0.6069\nEpoch 21/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.4720 - accuracy: 0.5884 - val_loss: 1.4839 - val_accuracy: 0.5910\nEpoch 22/50\n781/781 [==============================] - 34s 44ms/step - loss: 1.4461 - accuracy: 0.5943 - val_loss: 1.5059 - val_accuracy: 0.5905\nEpoch 23/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.4214 - accuracy: 0.5963 - val_loss: 1.5293 - val_accuracy: 0.5917\nEpoch 24/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.4051 - accuracy: 0.6018 - val_loss: 1.4343 - val_accuracy: 0.5993\nEpoch 25/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.3849 - accuracy: 0.6066 - val_loss: 1.5075 - val_accuracy: 0.5837\nEpoch 26/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.3635 - accuracy: 0.6111 - val_loss: 1.4292 - val_accuracy: 0.6093\nEpoch 27/50\n781/781 [==============================] - 32s 41ms/step - loss: 1.3540 - accuracy: 0.6127 - val_loss: 1.3940 - val_accuracy: 0.6214\nEpoch 28/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.3358 - accuracy: 0.6202 - val_loss: 1.3675 - val_accuracy: 0.6222\nEpoch 29/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.3275 - accuracy: 0.6180 - val_loss: 1.3556 - val_accuracy: 0.6286\nEpoch 30/50\n781/781 [==============================] - 32s 42ms/step - loss: 1.3030 - accuracy: 0.6287 - val_loss: 1.5624 - val_accuracy: 0.5832\nEpoch 31/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.2916 - accuracy: 0.6291 - val_loss: 1.3651 - val_accuracy: 0.6256\nEpoch 32/50\n781/781 [==============================] - 32s 41ms/step - loss: 1.2707 - accuracy: 0.6341 - val_loss: 1.4524 - val_accuracy: 0.6156\nEpoch 33/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.2698 - accuracy: 0.6346 - val_loss: 1.3938 - val_accuracy: 0.6231\nEpoch 34/50\n781/781 [==============================] - 32s 41ms/step - loss: 1.2568 - accuracy: 0.6368 - val_loss: 1.4362 - val_accuracy: 0.6166\nEpoch 35/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.2486 - accuracy: 0.6417 - val_loss: 1.5777 - val_accuracy: 0.5854\nEpoch 36/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.2353 - accuracy: 0.6461 - val_loss: 1.4038 - val_accuracy: 0.6193\nEpoch 37/50\n781/781 [==============================] - 32s 41ms/step - loss: 1.2166 - accuracy: 0.6501 - val_loss: 1.4788 - val_accuracy: 0.6076\nEpoch 38/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.2035 - accuracy: 0.6520 - val_loss: 1.4030 - val_accuracy: 0.6244\nEpoch 39/50\n781/781 [==============================] - 32s 41ms/step - loss: 1.1975 - accuracy: 0.6529 - val_loss: 1.3382 - val_accuracy: 0.6326\nEpoch 40/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.1967 - accuracy: 0.6545 - val_loss: 1.3459 - val_accuracy: 0.6368\nEpoch 41/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.1830 - accuracy: 0.6573 - val_loss: 1.3425 - val_accuracy: 0.6377\nEpoch 42/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.1719 - accuracy: 0.6591 - val_loss: 1.3187 - val_accuracy: 0.6408\nEpoch 43/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.1631 - accuracy: 0.6635 - val_loss: 1.4457 - val_accuracy: 0.6159\nEpoch 44/50\n781/781 [==============================] - 34s 43ms/step - loss: 1.1429 - accuracy: 0.6679 - val_loss: 1.2425 - val_accuracy: 0.6583\nEpoch 45/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.1437 - accuracy: 0.6684 - val_loss: 1.3448 - val_accuracy: 0.6378\nEpoch 46/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.1403 - accuracy: 0.6646 - val_loss: 1.3905 - val_accuracy: 0.6335\nEpoch 47/50\n781/781 [==============================] - 33s 43ms/step - loss: 1.1214 - accuracy: 0.6744 - val_loss: 1.2603 - val_accuracy: 0.6529\nEpoch 48/50\n781/781 [==============================] - 34s 43ms/step - loss: 1.1175 - accuracy: 0.6736 - val_loss: 1.2112 - val_accuracy: 0.6660\nEpoch 49/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.1096 - accuracy: 0.6774 - val_loss: 1.2475 - val_accuracy: 0.6557\nEpoch 50/50\n781/781 [==============================] - 33s 42ms/step - loss: 1.1001 - accuracy: 0.6778 - val_loss: 1.2808 - val_accuracy: 0.6472\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 6: Evaluate the Model","metadata":{}},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:07:17.010697Z","iopub.execute_input":"2023-08-02T20:07:17.011077Z","iopub.status.idle":"2023-08-02T20:07:19.964620Z","shell.execute_reply.started":"2023-08-02T20:07:17.011041Z","shell.execute_reply":"2023-08-02T20:07:19.963385Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 1s 4ms/step - loss: 1.2808 - accuracy: 0.6472\nTest Accuracy: 64.72%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 7: Fine-tuning","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}