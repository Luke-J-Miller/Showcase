{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nfrom enum import Enum\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom collections import deque\nfrom itertools import product\nfrom copy import deepcopy\nimport matplotlib.colors as mcolors\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-08T19:12:22.641823Z","iopub.execute_input":"2023-08-08T19:12:22.642235Z","iopub.status.idle":"2023-08-08T19:12:22.649511Z","shell.execute_reply.started":"2023-08-08T19:12:22.642203Z","shell.execute_reply":"2023-08-08T19:12:22.648640Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\ndef plot_series(iterations_per_episode, scores_per_episode):\n    plt.figure(figsize=(12, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(iterations_per_episode)\n    plt.title(\"Iterations per Episode\")\n    plt.xlabel(\"Episode\")\n    plt.ylabel(\"Iterations\")\n\n    plt.subplot(1, 2, 2)\n    plt.plot(scores_per_episode)\n    plt.title(f\"Score per {PRINT_FREQUENCY} Episodes\")\n    plt.xlabel(f\"Episodes time {PRINT_FREQUENCY}\")\n    plt.ylabel(\"Score\")\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:12:22.722926Z","iopub.execute_input":"2023-08-08T19:12:22.724169Z","iopub.status.idle":"2023-08-08T19:12:22.732677Z","shell.execute_reply.started":"2023-08-08T19:12:22.724125Z","shell.execute_reply":"2023-08-08T19:12:22.731113Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def plot_game_board(grid):\n    \"\"\"\n    Visualizes the game board using matplotlib.\n\n    Args:\n    - grid (2D list): The game grid.\n    \"\"\"\n    \n    # Convert the grid to numpy array for easier indexing\n    grid = np.array(grid)\n\n    # Define a colormap: list of color names\n    cmap = mcolors.ListedColormap(['white', 'black', 'green', 'red', 'yellow'])  # The order has been adjusted based on the value assignments below.\n    \n    # Set the bounds for the colormap\n    bounds = [-0.5, 0.5, 1.5, 2.5, 3.5, 4.5]\n    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n\n    # Plot\n    fig, ax = plt.subplots()\n    ax.imshow(grid, cmap=cmap, norm=norm)\n\n    # Hide the axis\n    ax.axis('off')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:12:22.808028Z","iopub.execute_input":"2023-08-08T19:12:22.808451Z","iopub.status.idle":"2023-08-08T19:12:22.816084Z","shell.execute_reply.started":"2023-08-08T19:12:22.808416Z","shell.execute_reply":"2023-08-08T19:12:22.814931Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Editable Globals\nPLAYABLE_GRID_SIZE = 10 # Playable grid without walls.  Minimum value = 5\n\n\nWALL_PENALTY = -0.1\nMOVEMENT_BONUS_NUMERATOR = 1  # This is divided by the distance to the apple\nAPPLE_BONUS = .5\nWIN_BONUS = 10\nSTARTING_SCORE = 0\n\n\nDECAY_RATE = (1 - 1e-6)\nLEARNING_RATE = 1e-2\nEPSILON = 9 * 1e-1\nPRINT_FREQUENCY = 2**12\nBUFFER_SIZE = 4096\nBATCH_SIZE = 8192\nGAMMA = 0.99\nEPISODES = 2**18\nSEED = 42\n\n# These globals are derived, don't edit unless refactoring\nTOTAL_GRID_SIZE = PLAYABLE_GRID_SIZE + 2             # Playable Area + Walls\nMAX_SNAKE_LENGTH = PLAYABLE_GRID_SIZE ** 2 - 1\n\nEMPTY_GRID_SET = set((i, j) for i, j in product(range(1, TOTAL_GRID_SIZE - 1), repeat=2))\n\n## initialize blank grid with empty squares (0) and walls (4)\nEMPTY_STATE_NESTED_LIST = [[0 for _ in range(TOTAL_GRID_SIZE)] for _ in range(TOTAL_GRID_SIZE)]\nfor i in range(TOTAL_GRID_SIZE):\n    EMPTY_STATE_NESTED_LIST[0][i] = EMPTY_STATE_NESTED_LIST[i][0] = EMPTY_STATE_NESTED_LIST[TOTAL_GRID_SIZE -1][i] = EMPTY_STATE_NESTED_LIST[i][TOTAL_GRID_SIZE - 1] = 1\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:12:22.888744Z","iopub.execute_input":"2023-08-08T19:12:22.889162Z","iopub.status.idle":"2023-08-08T19:12:22.899558Z","shell.execute_reply.started":"2023-08-08T19:12:22.889129Z","shell.execute_reply":"2023-08-08T19:12:22.898259Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n\nclass Direction(Enum):\n    UP =    [1, 0, 0, 0]\n    DOWN =  [0, 1, 0, 0]\n    LEFT =  [0, 0, 1, 0]\n    RIGHT = [0, 0, 0, 1]\n\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndef eat_apple(snake_queue):\n    \"\"\"\n    Generate a new apple location that's not within the snake's current position.\n\n    Args:\n    - snake_queue (list): List of tuples representing the snake's current positions.\n\n    Returns:\n    - tuple: New apple location.\n    \"\"\"\n    available_locations = EMPTY_GRID_SET - set(snake_queue)\n    new_apple_location = random.choice(list(available_locations))\n    return new_apple_location\n\ndef initialize_game(starting_head_location, starting_apple_location):\n    \"\"\"\n    Initialize the snake's starting position and the first apple's position.\n\n    Returns:\n    - snake_queue (list): List of tuples representing the snake's initial position.\n    - apple_location (tuple): Initial apple location.\n    \"\"\"\n    # Initialize the snake queue with the head location\n    snake_queue = [starting_head_location]\n    apple_location = starting_apple_location\n    score = STARTING_SCORE\n    distance_to_apple = ((starting_head_location[0]-starting_apple_location[0])**2 + (starting_head_location[1]-starting_apple_location[1])**2)**0.5\n    distance_traveled_to_apple = 0\n    game_over = False\n    return game_over, snake_queue, apple_location, distance_traveled_to_apple, distance_to_apple, score\n\ndef update_state(snake_queue, apple_location, distance_traveled_to_apple, direction, score):\n    \"\"\"\n    Update the snake's position based on the given direction.\n    \"\"\"\n    \n    def move_snake(snake_queue, direction):\n        head_location = snake_queue[-1]\n        # Update head_location based on the direction\n        if direction == Direction.UP: # Up\n            head_location = (head_location[0]-1, head_location[1])\n        elif direction == Direction.DOWN: # Down\n            head_location = (head_location[0]+1, head_location[1])\n        elif direction == Direction.LEFT: # Left\n            head_location = (head_location[0], head_location[1]-1)\n        else: # Right\n            head_location = (head_location[0], head_location[1]+1)\n        return head_location\n\n    def score_and_process_move(head_location, snake_queue, apple_location, distance_traveled_to_apple, score):\n        # Check if snake ate itself or a wall\n        distance_traveled_to_apple += 1\n        distance_to_apple = ((head_location[0]-apple_location[0])**2 + (head_location[1]-apple_location[1])**2)**0.5\n\n        if (head_location in snake_queue) or (head_location[0] in [0, TOTAL_GRID_SIZE - 1] or head_location[1] in [0, TOTAL_GRID_SIZE - 1]):\n            score += WALL_PENALTY\n            snake_queue.append(head_location)\n            snake_queue.pop(0)\n            return True, snake_queue, apple_location, distance_traveled_to_apple, score\n        # Check if snake ate apple\n        elif head_location == apple_location:\n            score += APPLE_BONUS \n            apple_location = eat_apple(snake_queue)\n            snake_queue.append(head_location)\n            distance_traveled_to_apple = 0\n        # Snake just moves\n        else:\n            score += MOVEMENT_BONUS_NUMERATOR // distance_to_apple\n            snake_queue.append(head_location)\n            snake_queue.pop(0)\n        if len(snake_queue) == MAX_SNAKE_LENGTH:\n            score += WIN_BONUS\n            return True, snake_queue, apple_location, distance_traveled_to_apple, score\n        return False, snake_queue, apple_location, distance_traveled_to_apple, score\n\n    return score_and_process_move(move_snake(snake_queue, direction), snake_queue, apple_location, distance_traveled_to_apple, score)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:12:22.967546Z","iopub.execute_input":"2023-08-08T19:12:22.967963Z","iopub.status.idle":"2023-08-08T19:12:22.989214Z","shell.execute_reply.started":"2023-08-08T19:12:22.967930Z","shell.execute_reply":"2023-08-08T19:12:22.987860Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class DQN(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(DQN, self).__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 256),\n            nn.ReLU(),\n            nn.Linear(256, output_dim)\n        )\n    \n    def forward(self, x):\n        return self.fc(x)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:12:23.044911Z","iopub.execute_input":"2023-08-08T19:12:23.045977Z","iopub.status.idle":"2023-08-08T19:12:23.053536Z","shell.execute_reply.started":"2023-08-08T19:12:23.045921Z","shell.execute_reply":"2023-08-08T19:12:23.052604Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class ReplayBuffer:\n    def __init__(self, capacity):\n        self.buffer = deque(maxlen=capacity)\n    \n    def push(self, state, action, reward, next_state, done):\n        experience = (state, action, reward, next_state, done)\n        self.buffer.append(experience)\n    \n    def sample(self, batch_size):\n        state_batch, action_batch, reward_batch, next_state_batch, done_batch = zip(\n            *random.sample(self.buffer, batch_size))\n        return state_batch, action_batch, reward_batch, next_state_batch, done_batch\n    \n    def __len__(self):\n        return len(self.buffer)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:12:23.242201Z","iopub.execute_input":"2023-08-08T19:12:23.242879Z","iopub.status.idle":"2023-08-08T19:12:23.251433Z","shell.execute_reply.started":"2023-08-08T19:12:23.242830Z","shell.execute_reply":"2023-08-08T19:12:23.250156Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class DQNAgent:\n    def __init__(self, input_dim, output_dim, gamma=GAMMA, learning_rate=LEARNING_RATE, buffer_size=BUFFER_SIZE, batch_size=BATCH_SIZE):\n        self.dqn = DQN(input_dim, output_dim).to(device)\n        self.target = DQN(input_dim, output_dim).to(device)\n        self.target.load_state_dict(self.dqn.state_dict())\n        self.target.eval() # Set the target network to evaluation mode\n        \n        self.optimizer = optim.Adam(self.dqn.parameters(), lr=learning_rate)\n        self.loss_fn = nn.MSELoss()\n        self.buffer = ReplayBuffer(buffer_size)\n        self.batch_size = batch_size\n        self.gamma = gamma\n        self.epsilon = EPSILON\n    \n    def update(self):\n        if len(self.buffer) < self.batch_size:\n            return\n        state, action, reward, next_state, done = self.buffer.sample(self.batch_size)\n        \n        # Convert to tensors\n        state = torch.FloatTensor(state).to(device)\n        action = torch.LongTensor(action).to(device)\n        reward = torch.FloatTensor(reward).to(device)\n        next_state = torch.FloatTensor(next_state).to(device)\n        done = torch.FloatTensor(done).to(device)\n        \n        # Compute Q-values\n        curr_Q = self.dqn(state).gather(1, action.unsqueeze(1))\n        curr_Q = curr_Q.squeeze(1)\n        next_Q = self.target(next_state).max(1)[0]\n        expected_Q = reward + (1 - done) * self.gamma * next_Q\n        \n        # Compute loss and update the network\n        loss = self.loss_fn(curr_Q, expected_Q.detach())\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n        \n    def get_action(self, state):\n        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n        with torch.no_grad():\n            if random.random() > self.epsilon:\n                action_index = int(self.dqn(state).max(1)[1])\n            else:\n                action_index = random.randint(0, 3) # Number of actions - 1\n\n        # Map action_index to Direction enum\n        \n        return action_index\n\n                \n    def decay_epsilon(self):\n        self.epsilon *= DECAY_RATE\n        self.epsilon = max(self.epsilon, 0.01)\n\n        # Decay the learning rate\n        #self.optimizer.param_groups[0]['lr'] *= DECAY_RATE\n\n    def get_epsilon(self):\n        return self.epsilon\n    def get_lr(self):\n        return self.optimizer.param_groups[0]['lr']        \n    def sync_target(self):\n        self.target.load_state_dict(self.dqn.state_dict())","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:12:23.320726Z","iopub.execute_input":"2023-08-08T19:12:23.321522Z","iopub.status.idle":"2023-08-08T19:12:23.339305Z","shell.execute_reply.started":"2023-08-08T19:12:23.321480Z","shell.execute_reply":"2023-08-08T19:12:23.337938Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def encode_state(snake_queue, apple_location, distance_traveled_to_apple, score):\n    \n    grid = [row[:] for row in EMPTY_STATE_NESTED_LIST]\n    \n    \n    for segment in snake_queue:\n        grid[segment[0]][segment[1]] = 2\n\n    grid[apple_location[0]][apple_location[1]] = 3\n    \n    head = snake_queue[-1]\n    grid[head[0]][head[1]] = 4\n\n\n    # Distance to nearest obstacle\n    distances_to_obstacle = {\n        \"left\": head[1],\n        \"right\": TOTAL_GRID_SIZE - 1 - head[1],\n        \"up\": head[0],\n        \"down\": TOTAL_GRID_SIZE - 1 - head[0]\n    }\n    \n    for segment in snake_queue:\n        if segment[0] == head[0]:  # Same row as head\n            if 0 < segment[1] - head[1] < distances_to_obstacle[\"right\"]:  # Segment is to the right of head\n                distances_to_obstacle[\"right\"] = segment[1] - head[1] - 1\n            elif 0 < head[1] - segment[1] < distances_to_obstacle[\"left\"]:  # Segment is to the left of head\n                distances_to_obstacle[\"left\"] = head[1] - segment[1] - 1\n                \n        if segment[1] == head[1]:  # Same column as head\n            if 0 < segment[0] - head[0] < distances_to_obstacle[\"down\"]:  # Segment is below head\n                distances_to_obstacle[\"down\"] = segment[0] - head[0] - 1\n            elif 0 < head[0] - segment[0] < distances_to_obstacle[\"up\"]:  # Segment is above head\n                distances_to_obstacle[\"up\"] = head[0] - segment[0] - 1\n\n    # Distance to apple (vertical and horizontal)\n    apple_dist = {\n        \"horizontal\": apple_location[1] - head[1],\n        \"vertical\": apple_location[0] - head[0]\n    }\n    \n    flat_grid = [cell for row in grid for cell in row]\n    \n    state = flat_grid + [distances_to_obstacle[dir] for dir in [\"left\", \"right\", \"up\", \"down\"]] + [apple_dist[\"horizontal\"], apple_dist[\"vertical\"]]\n    \n    return state\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:12:23.424230Z","iopub.execute_input":"2023-08-08T19:12:23.424655Z","iopub.status.idle":"2023-08-08T19:12:23.439707Z","shell.execute_reply.started":"2023-08-08T19:12:23.424605Z","shell.execute_reply":"2023-08-08T19:12:23.438018Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\n\ninput_dim = TOTAL_GRID_SIZE**2 + 6\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Number of GPUs: {torch.cuda.device_count()}')\nprint(f'Device: {device}')\nagent = DQNAgent(input_dim=input_dim , output_dim=4) # Fill input dimension\naction_mapping = {\n            0: Direction.UP,\n            1: Direction.DOWN,\n            2: Direction.LEFT,\n            3: Direction.RIGHT\n        }\niterations_plot_list = []\nscores_plot_list = []\nmoving_avg_iterations = deque(maxlen=PRINT_FREQUENCY)\nmoving_avg_scores = deque(maxlen=PRINT_FREQUENCY)\nmoving_avg_length = deque(maxlen=PRINT_FREQUENCY)\nfor episode in range(EPISODES):\n    set_seed(SEED + episode)\n    starting_head_location = random.choice(list(EMPTY_GRID_SET))\n    starting_apple_location = random.choice(list(EMPTY_GRID_SET - set(starting_head_location)))\n    iteration_count = 0\n    done, snake_queue, apple_location, distance_traveled_to_apple, distance_to_apple, score = initialize_game(starting_head_location, starting_apple_location)\n    state = encode_state(snake_queue, apple_location, distance_traveled_to_apple, score)\n\n    while not done:\n        iteration_count += 1\n        action_index = agent.get_action(state)\n        done, snake_queue, apple_location, distance_traveled_to_apple, new_score = update_state(snake_queue, apple_location, distance_traveled_to_apple, action_mapping[action_index], score)\n        next_state = encode_state(snake_queue, apple_location, distance_traveled_to_apple, new_score-score)\n        agent.buffer.push(next_state, action_index, new_score - score, next_state, done)\n        agent.update()\n        state = next_state\n        #game_grid = [state[i:i+TOTAL_GRID_SIZE] for i in range(0, TOTAL_GRID_SIZE**2, TOTAL_GRID_SIZE)]\n        #plot_game_board(game_grid)\n        score = new_score\n    \n    moving_avg_iterations.append(iteration_count)\n    moving_avg_scores.append(score)\n    moving_avg_length.append(len(snake_queue))\n    \n    plot_board = True\n    if ((episode + 1) % PRINT_FREQUENCY == 0):\n        avg_iterations = sum(moving_avg_iterations) / len(moving_avg_iterations)\n        avg_score = sum(moving_avg_scores) / len(moving_avg_scores)\n        avg_length = sum(moving_avg_length)/ len(moving_avg_length)\n        iterations_plot_list.append(avg_iterations)\n        scores_plot_list.append(avg_score)\n        print(f'''Episode: {episode} \n        Avg Iterations (last {PRINT_FREQUENCY} episodes): {avg_iterations:.2f} \n        Avg Score (last {PRINT_FREQUENCY}): {avg_score:.4f} \n        SnakeLength: {avg_length} \n        Eplsilon: {agent.get_epsilon()} \n        Learning Rate: {agent.get_lr()}\n        ''')\n        if plot_board:\n            game_grid = [state[i:i+TOTAL_GRID_SIZE] for i in range(0, TOTAL_GRID_SIZE**2, TOTAL_GRID_SIZE)]\n            plot_game_board(game_grid)\n    agent.decay_epsilon()\n    if episode % 2**8 == 0: # Sync every 10 episodes\n        agent.sync_target()\n\nplot_series(iterations_plot_list, scores_plot_list)\ngame_grid = [state[i:i+TOTAL_GRID_SIZE] for i in range(0, TOTAL_GRID_SIZE**2, TOTAL_GRID_SIZE)]\nplot_game_board(game_grid)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:12:23.510761Z","iopub.execute_input":"2023-08-08T19:12:23.511784Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Number of GPUs: 0\nDevice: cpu\nEpisode: 4095 \n        Avg Iterations (last 4096 episodes): 16.66 \n        Avg Score (last 4096): 0.3229 \n        SnakeLength: 1.10595703125 \n        Eplsilon: 0.8963220339360848 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFNUlEQVR4nO3bMW7DMBBFQTHg/a+86V5pq4hDA5qpCeh3D1tozcxcAHBd18/pAQB8D1EAIKIAQEQBgIgCABEFACIKAEQUAMi++3Ct9ckdAHzYnX+VXQoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgOzTA+6YmdMTAP7EWuv0hJdcCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJB9esAta5379sy5bwP8M5cCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACD79IBbZk4vAHgElwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADIPj0A4ElmTi94zaUAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAGSfHgDwJGud+/bM+zcuBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIPv0gDvWWqcnADyCSwGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkH334cx8cgcAX8ClAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAfgGjsxgSfAul9AAAAABJRU5ErkJggg=="},"metadata":{}},{"name":"stdout","text":"Episode: 8191 \n        Avg Iterations (last 4096 episodes): 17.02 \n        Avg Score (last 4096): 0.3380 \n        SnakeLength: 1.10546875 \n        Eplsilon: 0.8926582056957006 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFLElEQVR4nO3bMYrDUBAFQf1F97/ybNahUWKPwVWxQC+waSbQmZm5AOC6rr/tAQB8D1EAIKIAQEQBgIgCABEFACIKAEQUAMj99MFzzjt3wLrNzzj9vfiEJ98quxQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCALm3BzwxM9sT4K38xH/HOWd7wksuBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCALm3BwDLztl578zOe3nJpQBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyL09AFg2s72AL+JSACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgNzbA54452xPAPgJLgUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQO6nD87MO3cA8AVcCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoA5B8eXxgO3bmvfgAAAABJRU5ErkJggg=="},"metadata":{}},{"name":"stdout","text":"Episode: 12287 \n        Avg Iterations (last 4096 episodes): 16.43 \n        Avg Score (last 4096): 0.3222 \n        SnakeLength: 1.093994140625 \n        Eplsilon: 0.8890093538107648 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFNElEQVR4nO3bMW7DQBAEQZ7B/395nXUoM7CwAlQVH8DJGhvwzMxcAHBd18/2AAA+hygAEFEAIKIAQEQBgIgCABEFACIKAOR++vCc884dALzZk3+VXQoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgNzbA56Yme0JAP/inLM94SWXAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQBybw8Alp2z892Zne/ykksBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJB7ewCwbGZ7AR/EpQBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyL09AOCbzGwveM2lAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADIvT0A4Jucs/ftmb/fuBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAg9/aAJ8452xMAvoJLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQ++nDmXnnDgA+gEsBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYD8Avq7GBIuuA8tAAAAAElFTkSuQmCC"},"metadata":{}},{"name":"stdout","text":"Episode: 16383 \n        Avg Iterations (last 4096 episodes): 16.59 \n        Avg Score (last 4096): 0.2971 \n        SnakeLength: 1.097412109375 \n        Eplsilon: 0.8853754170635548 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Episode: 20479 \n        Avg Iterations (last 4096 episodes): 16.76 \n        Avg Score (last 4096): 0.3246 \n        SnakeLength: 1.10595703125 \n        Eplsilon: 0.8817563344865778 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFNUlEQVR4nO3bMW7DMBBFQTHg/a+86V5nR0UMGtBMTUC/e9hCa2bmAoDrun5ODwDge4gCABEFACIKAEQUAIgoABBRACCiAED23YdrrU/uAODD7vyr7FIAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAGSfHnDHzJyeAPAv1lqnJ7zlUgAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYDs0wMAnmTm9IL3XAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgOzTAwCeZK1z3575+41LAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyD49gBfWOvftmXPfBo5yKQAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAsk8P4IWZ0wuAB3IpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQPbpAXestU5PAHgElwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIPvuw5n55A4AvoBLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGA/AJv4xgSiR8gWQAAAABJRU5ErkJggg=="},"metadata":{}},{"name":"stdout","text":"Episode: 24575 \n        Avg Iterations (last 4096 episodes): 16.26 \n        Avg Score (last 4096): 0.3343 \n        SnakeLength: 1.10205078125 \n        Eplsilon: 0.8781520453615635 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFNElEQVR4nO3bMW7DQBAEQZ7B/395nXUoM7CwAlQVH8DJGhvwzMxcAHBd18/2AAA+hygAEFEAIKIAQEQBgIgCABEFACIKAOR++vCc884dALzZk3+VXQoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgNzbA56Yme0JAP/inLM94SWXAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAOTeHgDwTWa2F7zmUgAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoA5N4eAPBNztn79szfb1wKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBA7u0BwLJzdr47s/NdXnIpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQBybw8Als1sL+CDuBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAg9/aAJ8452xMAvoJLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQ++nDmXnnDgA+gEsBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYD8AswdGBKuVvnGAAAAAElFTkSuQmCC"},"metadata":{}},{"name":"stdout","text":"Episode: 28671 \n        Avg Iterations (last 4096 episodes): 16.02 \n        Avg Score (last 4096): 0.3092 \n        SnakeLength: 1.0986328125 \n        Eplsilon: 0.8745624892184263 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFMElEQVR4nO3bMYrDQBBFQc0y979yb/ZwtCjxjkBVsUDfTh4daM3MXABwXdfP6QEAPIcoABBRACCiAEBEAYCIAgARBQAiCgBk331wrfXNHY916tO+l/7dwBfd+VbZpQBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyD494I6ZOT3h373wJ8MrrLVOT/iTSwGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyD49AB5jrXPvnjn3bvjgUgAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoAZJ8eAI8xc3oBHOdSACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBknx5wx1rr9ASAV3ApABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQCy7z44M9/cAcADuBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAMgvaCEYDnwxSzEAAAAASUVORK5CYII="},"metadata":{}},{"name":"stdout","text":"Episode: 32767 \n        Avg Iterations (last 4096 episodes): 16.18 \n        Avg Score (last 4096): 0.3382 \n        SnakeLength: 1.1005859375 \n        Eplsilon: 0.870987605834262 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFNUlEQVR4nO3bMW7DMBBFQTHg/a+86V5nR0UMGtBMTUC/e9hCa2bmAoDrun5ODwDge4gCABEFACIKAEQUAIgoABBRACCiAED23YdrrU/uAODD7vyr7FIAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAGSfHnDHzJyeAPAv1lqnJ7zlUgAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBA9ukBvLDWuW/PnPs2cJRLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQfXoAL8ycXgA8kEsBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAsk8PAHiSmdML3nMpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQCyTw8AeJK1zn175u83LgUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQPbpAXestU5PAHgElwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIPvuw5n55A4AvoBLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGA/AJdXhgS1kx4+wAAAABJRU5ErkJggg=="},"metadata":{}},{"name":"stdout","text":"Episode: 36863 \n        Avg Iterations (last 4096 episodes): 15.88 \n        Avg Score (last 4096): 0.3362 \n        SnakeLength: 1.104736328125 \n        Eplsilon: 0.8674273352323396 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFL0lEQVR4nO3bMWrEUBAFQX2j+195nHVoK1lmQVWxQC8QNBPozMxcAHBd18/2AAC+hygAEFEAIKIAQEQBgIgCABEFACIKAOR++uA555M7APiwJ/8quxQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCALm3BzwxM9sTeINz9t7tG3+Ns/mdPeBSACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDk3h4AX2NmewGscykAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJB7ewDAm8xsL/ibSwGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkHt7AMCbnLP37pn/n3EpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQO7tAU+cc7YnALyCSwGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkPvpgzPzyR0AfAGXAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA+QUexBgQcI9zNQAAAABJRU5ErkJggg=="},"metadata":{}},{"name":"stdout","text":"Episode: 40959 \n        Avg Iterations (last 4096 episodes): 16.78 \n        Avg Score (last 4096): 0.3423 \n        SnakeLength: 1.101806640625 \n        Eplsilon: 0.8638816176810846 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFJUlEQVR4nO3bMWrFQBAFQY3R/a88zjo0Cvy9wlTFgn1ZM4Fmd/cCgOu6vk4PAOA9RAGAiAIAEQUAIgoARBQAiCgAEFEAIPfTD2fmkzsA+LAn/yq7FACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAuU8PeGJ3T08A+BUzc3rCj1wKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEDu0wMA/tzM6QWv5VIAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAOQ+PQDgz+2ee3vm3NsPuBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCALlPD3hiZk5PAP6R3dML3sulAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADI7O6eHgHAO7gUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADIN243FQ42rvlGAAAAAElFTkSuQmCC"},"metadata":{}},{"name":"stdout","text":"Episode: 45055 \n        Avg Iterations (last 4096 episodes): 15.46 \n        Avg Score (last 4096): 0.2635 \n        SnakeLength: 1.087890625 \n        Eplsilon: 0.8603503936930882 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFOElEQVR4nO3bMWoEMRBFQcno/lduZw9H9gRetLBVsWB+9uhg9szMAoC11tftAQC8D1EAIKIAQEQBgIgCABEFACIKAEQUAMh5+nDv/codALzYk3+VXQoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgJzbA56YmdsTAP7F3vv2hF+5FACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQM7tAcBaa+973565923ejksBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJBzewCw1pq5vQDWWi4FAH4QBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAg5/YAgE8yc3vB71wKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCc2wMAPsne97498/cblwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCADm3Bzyx9749AeAjuBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCADlPH87MK3cA8AZcCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoA5BsncRgSe6yiJQAAAABJRU5ErkJggg=="},"metadata":{}},{"name":"stdout","text":"Episode: 49151 \n        Avg Iterations (last 4096 episodes): 16.51 \n        Avg Score (last 4096): 0.3011 \n        SnakeLength: 1.09423828125 \n        Eplsilon: 0.8568336040240981 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Episode: 53247 \n        Avg Iterations (last 4096 episodes): 15.77 \n        Avg Score (last 4096): 0.3039 \n        SnakeLength: 1.097412109375 \n        Eplsilon: 0.853331189672033 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFMUlEQVR4nO3bMW7EMBAEQdHg/7+8zjq0FfhAwaqKCWiia2xwa2bmAoDrur5ODwDgOUQBgIgCABEFACIKAEQUAIgoABBRACD77sO11id3APBhd/6r7FIAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAGSfHnDHzJyeAPAn1lqnJ/zIpQBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGA7NMDHm+tM9+dOfNd4NVcCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGA7NMDHm/m9ALgH3n6T4pLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQfXoAwJusde7bM7+/cSkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIPv0gDvWWqcnALyCSwGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkH334cx8cgcAD+BSACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAg3xKEGBDV76YKAAAAAElFTkSuQmCC"},"metadata":{}},{"name":"stdout","text":"Episode: 57343 \n        Avg Iterations (last 4096 episodes): 16.01 \n        Avg Score (last 4096): 0.2934 \n        SnakeLength: 1.098388671875 \n        Eplsilon: 0.8498430918759871 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFMUlEQVR4nO3bMYrkUBAFQf1F979yjZfmjJymmlWELdCjoUnK0JmZuQDguq5/2wMA+B6iAEBEAYCIAgARBQAiCgBEFACIKACQ++mD55xP7gDgw558q+xSACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDk3h7wxMxsT4D/1zk7733p//ps/d4PuRQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCALm3BwDLZrYX8EVcCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADIvT0A4E1mthf8zqUAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAMi9PQDgTc7Ze/fM38+4FACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQe3vAE+ec7QkAr+BSACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDkfvrgzHxyBwBfwKUAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEB+ABnSGBD7H1fQAAAAAElFTkSuQmCC"},"metadata":{}},{"name":"stdout","text":"Episode: 61439 \n        Avg Iterations (last 4096 episodes): 15.68 \n        Avg Score (last 4096): 0.3052 \n        SnakeLength: 1.098388671875 \n        Eplsilon: 0.8463692521152568 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFLklEQVR4nO3bMYrDQBBFQc0y979yb/bCRYk8Yl0VC/TBhkcHWjMzFwBc1/VzegAA7yEKAEQUAIgoABBRACCiAEBEAYCIAgDZdx9caz25gxc5+Tmjvxk85863yi4FACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAED26QF3zMzpCXyIn5r/bq11esKfXAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQCyTw94vbXOvHfmzHuBr+ZSACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBknx7wejOnFwB8jEsBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAsk8PuGOtdXoCwFdwKQAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAsu8+ODNP7gDgBVwKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDkF4eIGA4ednISAAAAAElFTkSuQmCC"},"metadata":{}},{"name":"stdout","text":"Episode: 65535 \n        Avg Iterations (last 4096 episodes): 15.50 \n        Avg Score (last 4096): 0.2983 \n        SnakeLength: 1.102783203125 \n        Eplsilon: 0.8429096121083343 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFNUlEQVR4nO3bMW7EMBAEQdHg/7+8zjq0FfhMAaqKCWiyxgZaMzMXAFzX9XV6AADPIQoARBQAiCgAEFEAIKIAQEQBgIgCANl3H661PrkDgA+786+ySwGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkH16wB0zc3oCwJ9Ya52e8COXAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAg+/QAgDeZOb3gZy4FACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACD79ACAN1nr3Ldnfn/jUgAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgDZpwc83lpnvjtz5rvAq7kUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgDZpwc83szpBQD/xqUAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgOzTA+5Ya52eAPAKLgUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQPbdhzPzyR0APIBLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAfAOgbBgSFASAggAAAABJRU5ErkJggg=="},"metadata":{}},{"name":"stdout","text":"Episode: 69631 \n        Avg Iterations (last 4096 episodes): 15.74 \n        Avg Score (last 4096): 0.2899 \n        SnakeLength: 1.09423828125 \n        Eplsilon: 0.8394641138119574 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFNUlEQVR4nO3bMW7DQBAEQa3B/395nXUoM7B0AlQVH8DJGhtwdncfAPB4PH5ODwDgc4gCABEFACIKAEQUAIgoABBRACCiAECuuw9n5pU7AHixO/8quxQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCALlOD7hjd09PAPgXM3N6wlMuBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBArtMDAN5u5vSCj+VSACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQBynR4A8Ha75749c+7bN7gUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQ6/QAgG+ye3rBcy4FACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACDX6QEA32Tm3Ld3/37jUgAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFAHKdHnDHzJyeAPAVXAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgFx3H+7uK3cA8AFcCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoA5BddahYWhUhV7QAAAABJRU5ErkJggg=="},"metadata":{}},{"name":"stdout","text":"Episode: 73727 \n        Avg Iterations (last 4096 episodes): 14.91 \n        Avg Score (last 4096): 0.2864 \n        SnakeLength: 1.087646484375 \n        Eplsilon: 0.8360326994201186 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFM0lEQVR4nO3bMWrEQBBFwRmj+1+5nT0c2UrkWVBVLNCHZXl0oD0zswBgrfV1egAAn0MUAIgoABBRACCiAEBEAYCIAgARBQBy3X1w7/3kDgAedudbZZcCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACDX6QF3zMzpCfCsvc+92//rX+2Tv/UNLgUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQK7TA4C11szpBbDWcikA8IMoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAINfpAQBvMnN6we9cCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAXKcHALzJ3ufePfP3My4FACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQBynR5wx9779ASAV3ApABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQBy3X1wZp7cAcAHcCkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJBv0lMYEFateg0AAAAASUVORK5CYII="},"metadata":{}},{"name":"stdout","text":"Episode: 77823 \n        Avg Iterations (last 4096 episodes): 15.50 \n        Avg Score (last 4096): 0.2983 \n        SnakeLength: 1.100830078125 \n        Eplsilon: 0.8326153113630999 \n        Learning Rate: 0.01\n        \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFMUlEQVR4nO3bMYrDQBBFQc0y979yb/bAya4SewyqigX6geDRgdbMzAUA13X9nB4AwPcQBQAiCgBEFACIKAAQUQAgogBARAGA7LsPrrXeuQOAN7vzr7JLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQfXrAHTNzegKfsta5d/vO+IB18hu/waUAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAMg+PQBezJxeAI/mUgAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYDs0wMAnmTm9IK/uRQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCANmnBwA8yVrn3j3z/zMuBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAsk8PuGOtdXoCwCO4FACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA2XcfnJl37gDgC7gUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADIL7CfGBChbXg4AAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"markdown","source":"Absolutely! Systematic hyperparameter tuning and debugging is crucial in reinforcement learning to ensure efficient learning. Let's outline a structured approach:\n\n1. Baseline and Simplification:\nStart with a simpler version of the problem. Perhaps a smaller grid or an environment where the apple is always in the same place.\nMake the network as simple as possible. Once you see it learning, gradually increase its complexity.\n2. Diagnosis:\nVisualizations: Visualize the agent's decisions over time. Is it exploring enough? Is it getting stuck in a loop?\nReward Analysis: Print the rewards obtained during each step. Is the agent getting the expected rewards for its actions?\nGradient Checks: Monitor the magnitude of the gradients. If they're too small, you might be dealing with vanishing gradients; if they're too large, exploding gradients.\nQ-value Analysis: Plot the Q-values over time. Are they diverging or converging? Are they increasing for the correct actions and decreasing for the incorrect ones?\nAction Distribution: Check the distribution of actions taken by the agent. Is it too biased towards one action? This can indicate that the agent has found a loophole in the reward system or isn't exploring enough.\n3. Hyperparameter Tuning:\nGrid Search: Start with broader ranges for hyperparameters like learning rate, epsilon decay, etc., and then narrow down.\nRandom Search: Sometimes better than grid search, as it can explore the hyperparameter space more diversely.\nBayesian Optimization: Tools like Optuna, Hyperopt, or frameworks like Ray Tune can be very efficient for hyperparameter tuning in RL.\n4. Incremental Changes:\nChange one thing at a time and observe its impact. If you adjust multiple things and something goes wrong (or right), you won't know what caused it.\n5. Check Environment Dynamics:\nEnsure there are no bugs in the environment itself, as these can majorly affect learning.\n6. Reproducibility:\nStart with established, reproducible baselines or reference implementations. If a well-known algorithm doesn't work in your environment, it's a strong signal that something might be off.\n7. Alternative Approaches:\nCurriculum Learning: Start with easier tasks and gradually move to complex ones.\nReward Shaping: Sometimes, a more frequent, intermediate reward can guide the agent better than a sparse reward.\nTransfer Learning: If you have a model trained on a similar task, you can fine-tune it on your current task.\n8. Review Model Architecture:\nEnsure that the architecture is suitable for the task. Sometimes a simple feed-forward network might not suffice, and you might need recurrent layers or other architectures.\nCheck the initialization methods for your neural network layers.\n9. Regular Monitoring and Logging:\nTools like TensorBoard or Weights & Biases can be invaluable. Log scalars like loss, average reward, epsilon, and more complex data like histograms of network weights, Q-values, or even images of the game state.\nRemember, in RL, especially in environments with high variance, it's often valuable to run multiple seeds (starting points) and average the results to ensure the changes you're observing aren't just due to randomness.\n\n\nYour model's performance seems to be fluctuating with a limited increase in average score and snake length over the episodes. Let's troubleshoot:\n\nLearning Rate and Decay: Your learning rate LEARNING_RATE = 1e-2 is relatively high for a deep learning problem, especially when it is decaying at every episode. As the learning rate drops, the model might make smaller and smaller updates, leading to slow or stalled learning. Consider using a slightly higher learning rate or decaying it less frequently.\n\nReward Structure: The reward structure plays a critical role in RL. Let's analyze:\n\nMOVEMENT_BONUS: It's quite high for just moving. This might encourage the snake to move around without necessarily targeting the apple.\nWALL_PENALTY: It's a good idea to penalize the snake for hitting the wall. However, consider the magnitude. Is -10 too low or too high relative to other rewards?\nWIN_BONUS: This bonus is huge compared to other rewards. While this can incentivize winning, the agent might never achieve this state if it's too focused on smaller rewards (like movement).\nEpsilon Decay: Your epsilon is decaying at a rate of 1e-5 which means it will approach its minimum quite slowly. This means that exploration will continue to dominate for many episodes. It might be worthwhile to allow the agent to exploit its knowledge sooner by adjusting the decay rate or setting a threshold episode after which epsilon decreases more rapidly.\n\nNetwork Architecture: We haven't seen the architecture of the DQN. The model's complexity, layers, and activation functions can impact its ability to learn. Consider experimenting with different architectures.\n\nReplay Buffer: How is your buffer implemented? Too small a buffer can cause the agent to forget previous experiences quickly. On the other hand, a very large buffer might make the agent focus too much on older experiences. Also, the sampling strategy can make a difference. Prioritized experience replay can sometimes enhance learning.\n\nInitialization: How are the weights of your DQN initialized? Poor initialization can hamper learning.\n\nTraining Frequency: Consider adjusting how often you sync the target network with the DQN. Syncing too frequently can lead to chasing a moving target, while too infrequent can slow down learning.\n\nExploration vs. Exploitation: Printing the epsilon value periodically will give insight into how much exploration vs. exploitation is being done. If it's still in a high exploration mode, consider adjusting the decay.\n\nEnvironment Dynamics: Ensure that the environment (like apple placement, snake initialization) does not have any bugs or undesired behaviors that can affect learning.\n\nVisual Analysis: Sometimes, it's beneficial to visually observe the agent in action. Look for any repetitive or strange behaviors.\n\nGrad Check: Ensure gradients aren't vanishing or exploding during backpropagation. This can be done by checking the norms of the gradients.\n\nAfter making any changes, it's essential to retrain and observe the agent's behavior. Remember, deep reinforcement learning can be sensitive to hyperparameters and often requires multiple iterations and tweaks for convergence.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}